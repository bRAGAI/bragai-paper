# bRAG AI (*repo wip ðŸš§ ðŸ”¨)

    REPOSITORY IS NOT FINALZED YET; PLEASE COME BACK LATER
    
    (PRESS THE 'WATCH' BUTTON ON TOP TO BE NOTIFIED ONCE THE REPOSITORY IS COMPLETED)

<!-- _This repository is for reference only. Any use, reproduction, modification, or discussion of the contents is strictly prohibited without written permission._ -->

## Abstract

Large Language Models (LLMs) have demonstrated significant capabilities in automating tasks such as code generation, documentation, and completion. However, their static pre-training paradigm limits their adaptability to domain-specific contexts and dynamic, evolving datasets. In this work, we present bRAG AI, a Retrieval-Augmented Generation (RAG) framework fine-tuned using parameter- efficient methods for domain-specific applications. Building upon Code Llama, we employed Low-Rank Adaptation (LoRA) and Quantization-aware LoRA (QLoRA) techniques to fine-tune the model on a curated dataset comprising the top 25 repos- itories from Hugging Faceâ€™s GitHub organization. These repositories provided a rich source of structured and unstructured code-based knowledge. By integrating a RAG pipeline, we enable real-time semantic retrieval from multi-format data sources, such as academic papers, GitHub repositories, and multimedia transcripts. Our results indicate that bRAG AI outperforms baseline models in tasks requiring contextual understanding, achieving significant improvements in retrieval accuracy and domain-specific adaptability while maintaining computational efficiency. The proposed framework highlights the potential of combining efficient fine-tuning techniques with dynamic retrieval to create robust, scalable LLM systems

[See Final Paper Here](./bRAGAI_Final_Paper.pdf)

**Video demo coming soon**

